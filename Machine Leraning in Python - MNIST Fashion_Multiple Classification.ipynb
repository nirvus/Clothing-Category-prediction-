{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - MNIST Fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lots of Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build predictive models in Python we use a set of libraries that are imported here. In particular **pandas** and **sklearn** are particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "from TAS_Python_Utilities import data_viz\n",
    "from TAS_Python_Utilities import data_viz_target\n",
    "from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd  # used\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a dictionary to store simple model perofrmance comparions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_accuracy_comparisons = dict()\n",
    "model_valid_accuracy_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40060</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38941</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38790</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "9292       6       0       0       0       0       0       0       0       0   \n",
       "7978       5       0       0       0       0       0       0       0       0   \n",
       "40060      1       0       0       0       0       0       0       0       0   \n",
       "38941      7       0       0       0       0       0       0       0       0   \n",
       "38790      2       0       0       0       0       0       0       0      17   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "9292        0    ...            0         0         0         0         0   \n",
       "7978        0    ...            0         0         0         0         0   \n",
       "40060       0    ...           57         0         0         0         0   \n",
       "38941       0    ...            0         0         0         0         0   \n",
       "38790      48    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "9292          0         0         0         0         0  \n",
       "7978          0         0         0         0         0  \n",
       "40060         0         0         0         0         0  \n",
       "38941         0         0         0         0         0  \n",
       "38790        66         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the distribution of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    649\n",
       "4    632\n",
       "6    613\n",
       "0    612\n",
       "8    594\n",
       "7    591\n",
       "2    588\n",
       "1    584\n",
       "5    581\n",
       "9    556\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.451833</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.033667</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>0.278667</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>2.254000</td>\n",
       "      <td>5.98600</td>\n",
       "      <td>...</td>\n",
       "      <td>35.811667</td>\n",
       "      <td>23.937333</td>\n",
       "      <td>17.067167</td>\n",
       "      <td>17.21650</td>\n",
       "      <td>22.329833</td>\n",
       "      <td>18.351167</td>\n",
       "      <td>8.977500</td>\n",
       "      <td>2.685000</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.845704</td>\n",
       "      <td>0.091285</td>\n",
       "      <td>0.123123</td>\n",
       "      <td>0.613131</td>\n",
       "      <td>1.606628</td>\n",
       "      <td>3.249990</td>\n",
       "      <td>4.095869</td>\n",
       "      <td>6.754935</td>\n",
       "      <td>14.373143</td>\n",
       "      <td>24.58641</td>\n",
       "      <td>...</td>\n",
       "      <td>58.406758</td>\n",
       "      <td>49.060863</td>\n",
       "      <td>42.315573</td>\n",
       "      <td>43.24293</td>\n",
       "      <td>51.264592</td>\n",
       "      <td>46.158039</td>\n",
       "      <td>31.021058</td>\n",
       "      <td>16.793842</td>\n",
       "      <td>9.575578</td>\n",
       "      <td>2.453544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>241.00000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      4.451833     0.001333     0.003167     0.033667     0.089500   \n",
       "std       2.845704     0.091285     0.123123     0.613131     1.606628   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000     7.000000     7.000000    35.000000    83.000000   \n",
       "\n",
       "            pixel5       pixel6       pixel7       pixel8      pixel9  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.00000   \n",
       "mean      0.211333     0.278667     0.730500     2.254000     5.98600   \n",
       "std       3.249990     4.095869     6.754935    14.373143    24.58641   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "max     113.000000   205.000000   185.000000   219.000000   242.00000   \n",
       "\n",
       "          ...          pixel775     pixel776     pixel777    pixel778  \\\n",
       "count     ...       6000.000000  6000.000000  6000.000000  6000.00000   \n",
       "mean      ...         35.811667    23.937333    17.067167    17.21650   \n",
       "std       ...         58.406758    49.060863    42.315573    43.24293   \n",
       "min       ...          0.000000     0.000000     0.000000     0.00000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.00000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.00000   \n",
       "75%       ...         60.000000    14.000000     0.000000     0.00000   \n",
       "max       ...        255.000000   247.000000   250.000000   241.00000   \n",
       "\n",
       "          pixel779     pixel780     pixel781     pixel782     pixel783  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean     22.329833    18.351167     8.977500     2.685000     0.878500   \n",
       "std      51.264592    46.158039    31.021058    16.793842     9.575578   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     242.000000   255.000000   237.000000   220.000000   199.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  6000.000000  \n",
       "mean      0.065500  \n",
       "std       2.453544  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max     155.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the descriptive features we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5084\n",
      "[ 5084 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPHEgRLxZ2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118d47940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n",
      "[ 692 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/ECmCD+QKcIPZIrwA5ki/ECmCD+Qqf8DlVZ7LHJggOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118edb198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "[ 1024 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEelJREFUeJzt3X2MXNV5BvDnndkP1rv+WNuwGOMaA05SFxkHTd2GEJqE\nJnIojUGqLNwqciuUTSKHNBJVi5w/ilRVtWiTFLUo0iZYMVVK0ooQ3AohwE3lRo0QizE2xEkw4BCb\nXa9tgj+wd3c+3v4x181i9r5nPHfu3Dt+n59k7e68c2aOZ+fZOzPnnnNEVUFE/hSy7gARZYPhJ3KK\n4SdyiuEncorhJ3KK4SdyiuEncorhJ3KK4Sdyqqudd1YU0bbeYYe4ZsUys17sLZr18omp2NqZ6Wmz\n7dmp+LYAUAucATqnt9es9/ddElvrGewz23b3DJj18tQps/72+InY2pHjx822naoCoKoqjVxXkpze\nKyLrADwAoAjgW6q61bp+r4he3vS9Xbx+8MgDZn3uikGzPvbkq7G1va8fNNu+8PrrZn26UjHrq5cv\nN+s3rlkVW/uNP4qvAcClSz9i1sdf/aFZ/8/7n4it3b99u9m2U40DmGow/E2/7BeRIoAHAXwKwCoA\nG0XE/m0SUW4kec+/FsABVX1NVacBfBfA+tZ0i4jSliT8SwH8csbPh6LL3kVEhkVkVERGqwnujIha\nK/XP31R1BMAIUH/Pn/b9EVFjkhz5DwOY+TH1ldFlRNQBkoT/OQArRWSFiPQAuBPAjtZ0i4jSlnSo\n71YA/4j6UN82Vf1b6/p5Hur7w1tuMetf/Mofx9ZW3Phps21v72KzXq1OmnXVmlnv6ppj1jvV5OSE\nWe/unmvWi0X7PALL+Jv/Ydb/7s/+2az/4Kmnmr7vJC5kqC/Re35VfQJA/GAqEeUWT+8lcorhJ3KK\n4SdyiuEncorhJ3KK4SdyKtE4/4XKcpz/92680ayP7HzUrHd1zTOq9jh8pXLGrIfaA/awrao97dZm\n//5D5yAUi/Hz9YHwOQr2bdvnL1Sr75h1kfiR7ELB7nfo/1UunzTrd6+706w/vWuXWW9WW6b0ElFn\nY/iJnGL4iZxi+ImcYviJnGL4iZxyM9T37Jg9RXPRopvN+vT0sdhaodBjti0U7OWtQ78DkYZGbuLu\nPUFbIDQMmazvoSHM0MJvoedu/O2HhkcrldNmvadnoVk/ffqnZv2GxfbzrVkc6iOiIIafyCmGn8gp\nhp/IKYafyCmGn8gphp/IqYtmx+y/+fznzfrg4IfMeqViT9EsFvtja6Ex4/B4tU019DfaGu8OTam1\nx8qTnoNgN7fbitj/71Df6ltIxtXs30loOnGlYm8P3tdn715cuuGG2Nro7t1m21bhkZ/IKYafyCmG\nn8gphp/IKYafyCmGn8gphp/IqaRbdB8EcApAFUBFVUvW9dOcz7/7mL0U8oIFv23WJyfHzbq13bNq\n2WwbHs8OnW4Rmp6d5poMad52siXJRYqB9tZYfvNrAQDhZcN7ei416ydOvBBbK11mbxdvadsW3ZGP\nqWr8ShdElEt82U/kVNLwK4BnROR5ERluRYeIqD2Svuy/SVUPi8hlAJ4WkZ+q6rvefEd/FIYBwH6H\nRkTtlOjIr6qHo68TAB4DsHaW64yoaklVSww/UX40HX4R6ReRuee+B/BJAC+1qmNElK4kL/uHADwW\nTensAvCvqvpkS3pFRKlrOvyq+hqA61vYl0RC66C/cPx/zfrg4O+Y9cnJsdha6FyJrq7QVtNTZj08\nZz69sfhkewYkve9kbxSt7cFD8/lDawlccslSs35s4r/M+pY7/96stwOH+oicYviJnGL4iZxi+Imc\nYviJnGL4iZxys0V3yFP/vc2sv+/mTbG1yckjZttK5W2z3ts7FGhvbxct0m1UQ0t328LTjZM8f9Kd\nqlytTsbWurvnmW1DW3C/+O//ZNY/veFLZj0t3KKbiIIYfiKnGH4ipxh+IqcYfiKnGH4ipxh+Iqc4\nzt+grZs3x9bW3/+XZttjbzxr1q+49g/Mern8K7Oeb/HPr9A5BKHnZq1mT4UuFOLPfzhz5nWz7caP\n2EtS/mz/frMe0tXTE1urTMdvLR7CcX4iCmL4iZxi+ImcYviJnGL4iZxi+ImcYviJnGrFLr0u3Pvg\ng7G1JYODZtsPbLaXBZ+amjDrXV39Zt0e785u6e3Q/YeWzy4U4sfCAaBWi5+vDwB9ffHLa39gzpVm\n25C+gQGzfva0vQZDkrH8VuGRn8gphp/IKYafyCmGn8gphp/IKYafyCmGn8ip4Di/iGwDcBuACVW9\nLrpsIYDvAbgKwEEAG1S1kyedY96iRWb95PHjsbUD4+Nm29LA+8x6tfqOWQ+tMd+pQltwJ5mvDwDV\n6tkL7lOjQuP4naCRI/+3Aaw777J7AexU1ZUAdkY/E1EHCYZfVXcBeOu8i9cD2B59vx3A7S3uFxGl\nrNn3/EOqOhZ9Pw7A3m+KiHIn8bn9qqoiErvYmogMAxgGAPsdHhG1U7NH/iMisgQAoq+xM1NUdURV\nS6paYviJ8qPZ8O8AcG7b2k0AHm9Nd4ioXYLhF5FHAPwYwPtF5JCI3AVgK4BPiMgrAH4/+pmIOkjw\nPb+qbowp3dLivnSsoydPmvWJA6NmfXD5NWY9NB5urW8vkvV8/njhdfkrZr1QsJ++5fKJC+5To6x1\n94F8zNcP4Rl+RE4x/EROMfxETjH8RE4x/EROMfxETnHp7kh5yp4+ann5jTfM+qIVvxW4BftvcGjI\ny9oG264BqrXAbdtDheGhRKtu33fotkNDhSI8tln46BA5xfATOcXwEznF8BM5xfATOcXwEznF8BM5\nxXH+SHdvr1m3lmpe0G9voX3swEtmfeHV15r18BLV9ni3Le0pv9bxxd6iOyy7cf5uTuklok7F8BM5\nxfATOcXwEznF8BM5xfATOcXwEznFcf4WWHnFFWZ9csLegntq6VGzPn9+yaxPT5+/j+qvhefbJzlH\nIFuhtQiKxTlt6kln4pGfyCmGn8gphp/IKYafyCmGn8gphp/IKYafyKngOL+IbANwG4AJVb0uuuw+\nAJ8FcG6AeouqPpFWJ9shybr9p86eNevXfvwOsz45+aZZr1TsrabteetZj+NbY/FJ1vwHVO0582fO\nvBa4fd8aOfJ/G8C6WS7/uqquif51dPCJPAqGX1V3AYg/hYyIOlKS9/x3i8heEdkmIoMt6xERtUWz\n4f8GgKsBrAEwBuCrcVcUkWERGRWR0aQrthFR6zQVflU9oqpVrc+s+CaAtcZ1R1S1pKqlYrO9JKKW\nayr8IrJkxo93ALCXpyWi3GlkqO8RAB8FsFhEDgH4awAfFZE1qI8jHQTwuRT7SEQpCIZfVTfOcvFD\nKfSlY3UX7Tc0Rw/9j1nvnTfPrPf3X2PW7Xnt6a7LrxpaO7/5toWCvZeCasWsF4vx+ylcv3q12fbF\nvXvNepJ9HvKCZ/gROcXwEznF8BM5xfATOcXwEznF8BM5xaW7I0mGbroCQ31zF9tbcIem3araJ0Zb\ny3OHlu4ODbeFhJcGt/pmP2612mTgvps/Z3TeHC7rzSM/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/\nkVMc52+BYsH+G1ouv223D2wlHRrnt9tmN44fUijYT79azd6COzSl1zq2FQK/s5Dunp5E7fOAR34i\npxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipzjO3wJzAmsBhLaSLhTsrQ7D4/zxf8PD4/Qh6S39XavZ\n4/Qi9tMz9LgUCvFj8fP6+sy2HvDIT+QUw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+RUcJxfRJYBeBjA\nEOoLzI+o6gMishDA9wBcBeAggA2q+qv0upquNOdnz517nVmv1aYC9dB4uPU33P77nvw8gOaF1hqw\ntx4HQucgWOv693Z3B27bVp62z93oBI0c+SsA7lHVVQB+F8BmEVkF4F4AO1V1JYCd0c9E1CGC4VfV\nMVXdHX1/CsB+AEsBrAewPbradgC3p9VJImq9C3rPLyJXAfgggGcBDKnqWFQaR/1tARF1iIbP7ReR\nAQCPAviyqp6c+V5RVVVEZn0DJyLDAIYBoPmd1Yio1Ro68otIN+rB/46qfj+6+IiILInqSwBMzNZW\nVUdUtaSqJYafKD+C4Zf6If4hAPtV9WszSjsAbIq+3wTg8dZ3j4jS0sjL/g8D+AyAfSKyJ7psC4Ct\nAP5NRO4C8AsAG9LpYnskGbrp7bIfxmKx36zXaqH7bn7p7lBb1bSH+qzjiz2UF9qCOzQUaLUfHBgw\n24ZcDEt3B8Ovqj9C/IDqLa3tDhG1C8/wI3KK4SdyiuEncorhJ3KK4SdyiuEncopLd7fA8ksvNev2\nlFugPlPaah+afppkG+7spvSGpxsnOzZZS39fe/nliW7by5ReIroIMfxETjH8RE4x/EROMfxETjH8\nRE4x/EROcZw/cubUqabbDq6+LHANeyw9tIR1aLw71N6+7dA4f6geuu8k5xEku23rcbvm+uVN9OfX\nylP2cuudgEd+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+Iqc4zh+pJJifPefK+YnuO7Q+fZg1Hp72\nfP2k5wkYLQPnNyRZ13/+KnsNhpCzp08nap8HPPITOcXwEznF8BM5xfATOcXwEznF8BM5xfATORUc\n5xeRZQAeBjCE+oDyiKo+ICL3AfgsgKPRVbeo6hNpdTTP+q+YZ9ZVK2Y9NKe+VrPb27cdWgsg1N6u\nh9cSiK9b4/CNUK0G6uXY2sDSZOdmXAwaOcmnAuAeVd0tInMBPC8iT0e1r6vqP6TXPSJKSzD8qjoG\nYCz6/pSI7AewNO2OEVG6Lug9v4hcBeCDAJ6NLrpbRPaKyDYRGYxpMywioyIyar9II6J2ajj8IjIA\n4FEAX1bVkwC+AeBqAGtQf2Xw1dnaqeqIqpZUtZT0DHYiap2Gwi/1nSIfBfAdVf0+AKjqEVWtav1T\nm28CWJteN4mo1YLhl/pH0Q8B2K+qX5tx+ZIZV7sDwEut7x4RpaWRT/s/DOAzAPaJyJ7osi0ANorI\nGtTHcg4C+FwqPewAC4c+ZNa7u0NDgfaQV7HYG2gf/2lKaJgwNFwWUizaTyFrm+xisS/Q1j42lcsn\nzbr1uM9fvNps60Ejn/b/CLNPynY5pk90seAZfkROMfxETjH8RE4x/EROMfxETjH8RE5x6e4W+Ivb\n/sSsf+GeDWZ9wW/ay0j3Diwy693dC2JrXV1zzbbWODwQno5cq9lLnler78TWpqbeNNuenbCXxz75\n6ltm/cS+idjak6MvmG094JGfyCmGn8gphp/IKYafyCmGn8gphp/IKYafyCkJL73cwjsTOQrgFzMu\nWgzgWNs6cGHy2re89gtg35rVyr4tV9WG9h9va/jfc+cio6payqwDhrz2La/9Ati3ZmXVN77sJ3KK\n4SdyKuvwj2R8/5a89i2v/QLYt2Zl0rdM3/MTUXayPvITUUYyCb+IrBORn4nIARG5N4s+xBGRgyKy\nT0T2iMhoxn3ZJiITIvLSjMsWisjTIvJK9HXWbdIy6tt9InI4euz2iMitGfVtmYj8UER+IiIvi8if\nR5dn+tgZ/crkcWv7y34RKQL4OYBPADgE4DkAG1X1J23tSAwROQigpKqZjwmLyM0ATgN4WFWviy67\nH8Bbqro1+sM5qKp/lZO+3QfgdNY7N0cbyiyZubM0gNsB/CkyfOyMfm1ABo9bFkf+tQAOqOprqjoN\n4LsA1mfQj9xT1V0Azl+xYj2A7dH321F/8rRdTN9yQVXHVHV39P0pAOd2ls70sTP6lYkswr8UwC9n\n/HwI+dryWwE8IyLPi8hw1p2ZxVC0bToAjAMYyrIzswju3NxO5+0snZvHrpkdr1uNH/i9102qugbA\npwBsjl7e5pLW37PlabimoZ2b22WWnaX/X5aPXbM7XrdaFuE/DGDZjJ+vjC7LBVU9HH2dAPAY8rf7\n8JFzm6RGX+MXqmuzPO3cPNvO0sjBY5enHa+zCP9zAFaKyAoR6QFwJ4AdGfTjPUSkP/ogBiLSD+CT\nyN/uwzsAbIq+3wTg8Qz78i552bk5bmdpZPzY5W7Ha1Vt+z8At6L+if+rAL6SRR9i+nU1gBejfy9n\n3TcAj6D+MrCM+mcjdwFYBGAngFcAPANgYY769i8A9gHYi3rQlmTUt5tQf0m/F8Ce6N+tWT92Rr8y\nedx4hh+RU/zAj8gphp/IKYafyCmGn8gphp/IKYafyCmGn8gphp/Iqf8DfGqw4IzZKE8AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130e6aac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2073\n",
      "[ 2073 ]  Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130c9bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732\n",
      "[ 732 ]  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130bc08d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n",
      "[ 977 ]  Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEVpJREFUeJzt3XuMnNV5x/Hf413vxbvG+ALrxTY2F9MGTHGQg6hiyK04\nmEbhoooEKZGTpphKgTZqlRSB1FI1lVATcvmjIjHBwiRcUglSaFMFgYVKaSuKoQZMzB0bvFmvr9i7\n9np3vfv0jx2ni/F53vXO7MyY8/1IK+/OM2fm+F3/PO/Mec855u4CkJ8pte4AgNog/ECmCD+QKcIP\nZIrwA5ki/ECmCD+QKcIPZIrwA5lqrOaTNZh5VZ8QyMxhScPuNp77lpVFM7tc0g8lNUj6ibvfXvRk\nc8t5QgCh7cdx3wmf9ptZg6R/lLRS0rmSrjOzcyf6eACqq5z3/BdJesPd33L3QUkPSrqyMt0CMNnK\nCf88Se+O+Xlb6bb3MbPVZrbBzDYMl/FkACpr0j9/c/c1ktZIUrMZ84eBOlHOK3+XpAVjfp5fug3A\nCaCc8D8rabGZnWFmTZK+KOnRynQLwGSb8Gm/ux82sxslPabRob617v5yxXoGYFJZNZfxajZzxvmB\nybNd0sA4L/Lh8l4gU4QfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4g\nU4QfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFM\nEX4gUxPeoluSzGyLpF5Jw5IOu/uySnQKwOQrK/wln3L3XRV4HABVxGk/kKlyw++SnjCz58xsdSU6\nBKA6yj3tX+7uXWZ2qqTHzewVd39q7B1K/ymslqSGMp8MQOWYu1fmgcxuk9Tn7t9N3afZzOdW5NkA\nHMt2SQPuNp77Tvi038zazGz6ke8lrZC0aaKPB6C6yjnt75D0CzM78jj3u/uvKtIrAJOuYqf948Fp\nPzC5qnLaD+DERviBTBF+IFOEH8gU4QcyRfiBTFViVh8KNDY11ey5Dw8OhvXW9vaw3t/XV9bz33Pr\nrcnavJWLw7bv/PLVsN61Z09Y/+sf/zisR06aPTusH+ztnfBjS9LU4N9Eucd8vHjlBzJF+IFMEX4g\nU4QfyBThBzJF+IFMEX4gU4zzV0HRWHuRousEoscvGq8eGhiYUJ+O+NLnPx/Wz/uzS5O1V+/8r7Dt\nR67/WFg/+cm3wrqCYf6iY1o0jl/0Oy16/Ggs/0ff+lbY9sYf/CBdHBoK247FKz+QKcIPZIrwA5ki\n/ECmCD+QKcIPZIrwA5linP8EUM51Avt37y7rua9duTKs/+l3vhzWzdKvL2d86ffCtv0743nt1hi/\ndp22cGGy9putW8O2szs7w/q+guNa9Dv77Cc+kaxNnz4tbPv9m25K1v7iZz8L247FKz+QKcIPZIrw\nA5ki/ECmCD+QKcIPZIrwA5kqHOc3s7WSPidph7svKd02S9LPJS2StEXSte6+d/K6iUi09v53brgh\nbHv25b8b1of64vHqob54PYDD/TuTtcF9h8K2pyz5SFifUjDOv+6+v03WLlv+lbDt7u7usF7kwTu+\nHdY7V5ydrB3aeSBsu+mnTydrQ4cPxx0bYzyv/PdIuvyo226WtN7dF0taX/oZwAmkMPzu/pSko7dG\nuVLSutL36yRdVeF+AZhkE33P3+HuR86LtkvqqFB/AFRJ2df2u7ubmafqZrZa0mpJaij3yQBUzERf\n+XvMrFOSSn/uSN3R3de4+zJ3X0b4gfox0fA/KmlV6ftVkh6pTHcAVEth+M3sAUn/Lel3zGybmX1N\n0u2SLjOz1yX9QelnACeQwvf87n5dovSZ4342MzVOnZoszyhaYz6YI13uvPVaKlrj/U+uigdTVl7z\n8WTt/D+6Pmzb0/VYWN/1XFdYL5pT3zwzPTf9YNf+sG3X0/8bP3dDwXPPak3W1j9zb/zc//p6WJ9+\nzqywvuCzS8L6ns3vJmunXhBf33DgJ+uTtRFPfvz2AVzhB2SK8AOZIvxApgg/kCnCD2SK8AOZqqul\nu8tdDnkyXbViRbL2++ecE7Y964L0EtKS1LZwRlhvaEkPj0qSRtLDO+9s+ue46eGRsN7YHg9DDr4X\nT8vd/8bRc8LGzwv6NqUpvmb0wLv7krXZF54Wtl30hfPCetFU557/eTOsjwymp942N88N2/b29ydr\nwyPxMRuLV34gU4QfyBThBzJF+IFMEX4gU4QfyBThBzJV3XF+93Csfsn554fNP7UkPU3yzI54GcHT\nFp0a1tvPjqdoti2Ix+Ijw/1DYb1oCeve13aFdZuaHu9unzIzbDu0P156e0pT/PowsPtgWD/Und5m\n+6wvXBS23fXS22G96Li1dqSXNN9fcEwb2+LrGzTFwnLLKfE22yefOT/dtiW+BqFhSvp3Evfq/Xjl\nBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU1Ud5z+pvV2XXXhhsv7Nb381bD/4Xnoec0Nz/FdpnBbP\niS9aBrpoXDhUMCY8VDAn3ofj5Zgb2tLj/A0Fc94P9sbj/EVz6gd2xeP8C68+N1mbNi29TbUkDfW+\nEtatYFC7aWZLsjbjnDlh25bWeKy9aM59a+u8sL69+1/StXf/LWwbLc89/oW7eeUHskX4gUwRfiBT\nhB/IFOEHMkX4gUwRfiBTheP8ZrZW0uck7XD3JaXbbpN0vaSdpbvd4u7x4KSk1uZmLV20KFlvmtEc\ntu/v7k3Whg/Gc+ZHhuLxai9Y73yoN70OwZTGeMD58IG4b0Xrz7d0tIX1qSelx7OHCsbxp58Vr2PQ\nvz19zCVpaF/8+HM6P5GsDQz0hG0Xr7gmrDc0xHPmo/qhQ9vCtgcPvhXWBwa6w/rrjz0SP/7W9J4C\npyw/PWzb1pzOSTTX/2jjuec9ki4/xu3fd/elpa/C4AOoL4Xhd/enJE182xUAdamc9/w3mdmLZrbW\nzOK1ogDUnYmG/05JZ0paKqlb0h2pO5rZajPbYGYb+g7F17ADqJ4Jhd/de9x92N1HJN0lKbkSo7uv\ncfdl7r6svSX9wRSA6ppQ+M2sc8yPV0vaVJnuAKiW8Qz1PSDpk5LmmNk2SX8j6ZNmtlSjMwi3SLph\nEvsIYBIUht/drzvGzXdP5MkODQ7qla6uZP2kO58K21/wmfSe6Y1t8TUC0VoAUvFY/Mih9H7qwwUT\nyxta4nH8xvaCNeILHn842OvdCtqODKTbSsXXIExpjus9W9Yna62z4r0UBgZ2xPW+3WG9b+t7yZo1\nxie9U6fHv5Pdz8Xj/CPB70SSWuamr91oO+2ksO3eAweStcPDw2HbsbjCD8gU4QcyRfiBTBF+IFOE\nH8gU4QcyZR4sA1xpzWYeLXj81auvDtvv6U1PL114ajxsdMklF4T1ttMLtuBuSA+ZRcOAkjSlqWBE\nteC/4CkFw1KN09LDUlOnx0OgRctfF21V3dgaL4k+1Jee8lu0xfbA3nh4NppmLUnTOqcna62nprfv\nlqS+d9LDhFLxUKEPx1PEe9/cm6xF25pL0hMbNiZra558Ur/Zu3dcO3Xzyg9kivADmSL8QKYIP5Ap\nwg9kivADmSL8QKbqapy/tT0ee73xmvRSzo0N8dTSpzdvDuvTguWQJWnZ2entpM+eG2/X3D4/nqLZ\nelp6PFqSmmZMfAWk4YIpu/3b4zHlfa/F02bfC6aXStLGLVuStXd27kzWxvPYvQfj7cHbylg5qr21\nNay3NMXXP+wr6Hvk0vPSU9cl6fTZs5O1b95/v97o6WGcH0Aa4QcyRfiBTBF+IFOEH8gU4QcyRfiB\nTFV1nL+locEXTUtvm9zfF485R/7w058O6/ODsVFJmtkWb4O9bU96r9KNb78dth06HI+1F22rPLXg\nGoZDQ+llx4vGwgcG4znxzQXj2R9bvDisz58zJ1mbXXBdx5SC4xJtVS1Jvf3p9QD6C/7egwVLYE8r\nOC5F143MCHIw6+T4uo+7fvV4svbLF17Q7r4+xvkBpBF+IFOEH8gU4QcyRfiBTBF+IFOEH8hU4Ti/\nmS2QdK+kDkkuaY27/9DMZkn6uaRFkrZIutbd04uRq3g+fy1dcvHFYb3j5JOTtekFc7/PW7AgrEfj\n9FLxtsudQd/e3hFvc100b71owLhn376wHo21jxT82xssOC5NU+M9AyItBW2bGuO9For6fnAgvV+B\nJO0Lrr/4z5dfDtv2bNuWrG2XNOBesXH+w5L+0t3PlXSxpK+b2bmSbpa03t0XS1pf+hnACaIw/O7e\n7e7Pl77vlbRZ0jxJV0paV7rbOklXTVYnAVTecb3nN7NFkj4q6RlJHe7eXSpt1+jbAgAniIJN5P6f\nmbVLekjSN9x9v43Z5M3d3cyO+SbIzFZLWi1J8RXqAKppXK/8ZjZVo8G/z90fLt3cY2adpXqnpGN+\nsuTua9x9mbsvI/xA/SgMv42+xN8tabO7f29M6VFJq0rfr5L0SOW7B2CyjGeob7mk/5D0kqQj+w7f\notH3/f8k6XRJWzU61Jee96r6HuoDPgyOZ6ivrtbtB1CeSo/zA/gQIvxApgg/kCnCD2SK8AOZIvxA\npgg/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZ\nIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApgrDb2YLzOxJM/u1mb1sZn9euv02M+sy\ns42lrysmv7sAKsXcPb6DWaekTnd/3symS3pO0lWSrpXU5+7fHe+TNZv53HJ6CyC0XdKAu43nvo1F\nd3D3bkndpe97zWyzpHll9RBAzR3Xe34zWyTpo5KeKd10k5m9aGZrzWxmos1qM9tgZhuGy+oqgEoq\nPO3/7R3N2iX9u6S/d/eHzaxD0i5JLunvNPrW4I+jx+C0H5hcx3PaP65XfjObKukhSfe5+8OS5O49\n7j7s7iOS7pJ00QT7C6AGxvNpv0m6W9Jmd//emNs7x9ztakmbKt89AJOl8AM/SR+X9GVJL5nZxtJt\nt0i6zsyWavS0f4ukGyalhwAmxbjf81cC7/mByVXx9/wAPnwIP5Apwg9kivADmSL8QKYIP5Apwg9k\nivADmSL8QKYIP5Apwg9kivADmSL8QKYIP5Cpqk7pNbOdkraOuWmORpcCq0f12rd67ZdE3yaqkn1b\n6O6njOeOVQ3/B57cbIO7L6tZBwL12rd67ZdE3yaqVn3jtB/IFOEHMlXr8K+p8fNH6rVv9dovib5N\nVE36VtP3/ABqp9av/ABqpCbhN7PLzexVM3vDzG6uRR9SzGyLmb1U2nl4Q437stbMdpjZpjG3zTKz\nx83s9dKfx9wmrUZ9q4udm4OdpWt67Optx+uqn/abWYOk1yRdJmmbpGclXefuv65qRxLMbIukZe5e\n8zFhM7tUUp+ke919Sem2f5C0x91vL/3HOdPd/6pO+nabjnPn5knqW2pn6a+ohseukjteV0ItXvkv\nkvSGu7/l7oOSHpR0ZQ36Uffc/SlJe466+UpJ60rfr9PoP56qS/StLrh7t7s/X/q+V9KRnaVreuyC\nftVELcI/T9K7Y37epvra8tslPWFmz5nZ6lp35hg6StumS6N7NHTUsjPHULhzczUdtbN03Ry7iex4\nXWl84PdBy919qaSVkr5eOr2tSz76nq2ehmvulHSmpKWSuiXdUcvOlHaWfkjSN9x9/9haLY/dMfpV\nk+NWi/B3SVow5uf5pdvqgrt3lf7cIekXqr/dh3uObJJa+nNHjfvzW/W0c/OxdpZWHRy7etrxuhbh\nf1bSYjM7w8yaJH1R0qM16McHmFlb6YMYmVmbpBWqv92HH5W0qvT9KkmP1LAv71MvOzendpZWjY9d\n3e147e5V/5J0hUY/8X9T0q216EOiX2dKeqH09XKt+ybpAY2eBg5p9LORr0maLWm9pNclPSFpVh31\n7aeSXpL0okaD1lmjvi3X6Cn9i5I2lr6uqPWxC/pVk+PGFX5ApvjAD8gU4QcyRfiBTBF+IFOEH8gU\n4QcyRfiBTBF+IFP/Bxubcj5Ie0TMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e260f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3042\n",
      "[ 3042 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118dd5e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253\n",
      "[ 2253 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118dd55c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4168\n",
      "[ 4168 ]  Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130e18f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a sample of images from the dataset\n",
    "for i in range(0, 9):\n",
    "    i_rand = randint(0, X.shape[0])\n",
    "    print(i_rand)                \n",
    "    print(\"[\", i_rand, \"] \", classes[Y[i_rand]])\n",
    "    two_d = (X.iloc[i_rand].values.reshape(28, 28))\n",
    "    pyplot.imshow(two_d, cmap='pink')\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data (important for some models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a **training set**, a **vaidation set**, and a **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Very Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the decision tree so we can see what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(my_tree, feature_names, fileName='dt_over.png')\n",
    "#Image(filename='dt_over.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       299\n",
      "          1       1.00      1.00      1.00       283\n",
      "          2       1.00      1.00      1.00       285\n",
      "          3       1.00      1.00      1.00       350\n",
      "          4       1.00      1.00      1.00       305\n",
      "          5       1.00      1.00      1.00       297\n",
      "          6       1.00      1.00      1.00       295\n",
      "          7       1.00      1.00      1.00       321\n",
      "          8       1.00      1.00      1.00       288\n",
      "          9       1.00      1.00      1.00       277\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>299</td>\n",
       "      <td>283</td>\n",
       "      <td>285</td>\n",
       "      <td>350</td>\n",
       "      <td>305</td>\n",
       "      <td>297</td>\n",
       "      <td>295</td>\n",
       "      <td>321</td>\n",
       "      <td>288</td>\n",
       "      <td>277</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          299    0    0    0    0    0    0    0    0    0   299\n",
       "1            0  283    0    0    0    0    0    0    0    0   283\n",
       "2            0    0  285    0    0    0    0    0    0    0   285\n",
       "3            0    0    0  350    0    0    0    0    0    0   350\n",
       "4            0    0    0    0  305    0    0    0    0    0   305\n",
       "5            0    0    0    0    0  297    0    0    0    0   297\n",
       "6            0    0    0    0    0    0  295    0    0    0   295\n",
       "7            0    0    0    0    0    0    0  321    0    0   321\n",
       "8            0    0    0    0    0    0    0    0  288    0   288\n",
       "9            0    0    0    0    0    0    0    0    0  277   277\n",
       "All        299  283  285  350  305  297  295  321  288  277  3000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.716666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.69      0.69       124\n",
      "          1       0.90      0.91      0.91       132\n",
      "          2       0.56      0.59      0.58       112\n",
      "          3       0.73      0.79      0.76       126\n",
      "          4       0.61      0.59      0.60       120\n",
      "          5       0.81      0.87      0.84       115\n",
      "          6       0.43      0.42      0.42       129\n",
      "          7       0.73      0.72      0.73       107\n",
      "          8       0.88      0.84      0.86       122\n",
      "          9       0.83      0.75      0.79       113\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>122</td>\n",
       "      <td>133</td>\n",
       "      <td>117</td>\n",
       "      <td>137</td>\n",
       "      <td>117</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>116</td>\n",
       "      <td>103</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           85    1    4    5    3    0   25    0    1    0   124\n",
       "1            0  120    0    9    1    0    2    0    0    0   132\n",
       "2            4    0   66    4   23    0   12    0    3    0   112\n",
       "3            3    4    3  100    6    1    9    0    0    0   126\n",
       "4            0    3   17   13   71    0   15    0    1    0   120\n",
       "5            0    1    0    0    0  100    2    5    2    5   115\n",
       "6           28    3   22    6   12    0   54    0    4    0   129\n",
       "7            0    0    0    0    0   16    0   77    2   12   107\n",
       "8            2    0    5    0    1    4    7    0  102    1   122\n",
       "9            0    1    0    0    0    3    0   23    1   85   113\n",
       "All        122  133  117  137  117  124  126  105  116  103  1200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.727222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.75      0.74       189\n",
      "          1       0.93      0.93      0.93       169\n",
      "          2       0.60      0.66      0.63       191\n",
      "          3       0.69      0.80      0.74       173\n",
      "          4       0.58      0.53      0.56       207\n",
      "          5       0.81      0.76      0.79       169\n",
      "          6       0.44      0.38      0.41       189\n",
      "          7       0.79      0.88      0.83       163\n",
      "          8       0.86      0.84      0.85       184\n",
      "          9       0.91      0.83      0.86       166\n",
      "\n",
      "avg / total       0.73      0.73      0.72      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>15</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>197</td>\n",
       "      <td>170</td>\n",
       "      <td>211</td>\n",
       "      <td>199</td>\n",
       "      <td>189</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>182</td>\n",
       "      <td>179</td>\n",
       "      <td>151</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          142    0    2   12    5    1   24    0    3    0   189\n",
       "1            1  158    0   10    0    0    0    0    0    0   169\n",
       "2            5    1  126    4   32    0   20    0    3    0   191\n",
       "3            8    6    3  138    8    1    8    0    1    0   173\n",
       "4            5    2   47   15  110    0   24    0    4    0   207\n",
       "5            0    0    0    1    0  129    0   21    8   10   169\n",
       "6           36    3   27   15   32    1   72    0    3    0   189\n",
       "7            0    0    0    0    0   17    0  143    0    3   163\n",
       "8            0    0    6    2    2    4   14    1  154    1   184\n",
       "9            0    0    0    2    0    6    1   17    3  137   166\n",
       "All        197  170  211  199  189  159  163  182  179  151  1800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less Overiftted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree, setting min samples per leaf to a sensible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the decision tree so we can see what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualise the decision tree\n",
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(my_tree, feature_names, fileName=\"dt_under.png\")\n",
    "#Image(filename='dt_under.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.76      0.77       299\n",
      "          1       0.96      0.84      0.90       283\n",
      "          2       0.68      0.68      0.68       285\n",
      "          3       0.62      0.89      0.73       350\n",
      "          4       0.61      0.59      0.60       305\n",
      "          5       0.87      0.85      0.86       297\n",
      "          6       0.64      0.35      0.45       295\n",
      "          7       0.82      0.85      0.83       321\n",
      "          8       0.80      0.90      0.85       288\n",
      "          9       0.91      0.85      0.88       277\n",
      "\n",
      "avg / total       0.76      0.76      0.75      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>313</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>293</td>\n",
       "      <td>249</td>\n",
       "      <td>286</td>\n",
       "      <td>504</td>\n",
       "      <td>296</td>\n",
       "      <td>290</td>\n",
       "      <td>163</td>\n",
       "      <td>334</td>\n",
       "      <td>326</td>\n",
       "      <td>259</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          227    2    7   36    4    0    5    0   18    0   299\n",
       "1            1  239    2   40    0    0    0    0    1    0   283\n",
       "2            5    0  194    5   63    0    7    0   11    0   285\n",
       "3            1    8    2  313   12    0    9    0    5    0   350\n",
       "4            0    0   31   53  180    0   34    0    7    0   305\n",
       "5            0    0    0    4    0  252    0   35    2    4   297\n",
       "6           55    0   46   37   34    1  104    0   18    0   295\n",
       "7            0    0    0    0    0   27    0  273    1   20   321\n",
       "8            4    0    4    8    3    4    4    1  260    0   288\n",
       "9            0    0    0    8    0    6    0   25    3  235   277\n",
       "All        293  249  286  504  296  290  163  334  326  259  3000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.691666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75       124\n",
      "          1       0.96      0.86      0.90       132\n",
      "          2       0.55      0.59      0.57       112\n",
      "          3       0.57      0.92      0.71       126\n",
      "          4       0.50      0.49      0.50       120\n",
      "          5       0.74      0.77      0.75       115\n",
      "          6       0.55      0.26      0.35       129\n",
      "          7       0.69      0.69      0.69       107\n",
      "          8       0.80      0.81      0.81       122\n",
      "          9       0.85      0.77      0.81       113\n",
      "\n",
      "avg / total       0.70      0.69      0.68      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>130</td>\n",
       "      <td>118</td>\n",
       "      <td>121</td>\n",
       "      <td>202</td>\n",
       "      <td>117</td>\n",
       "      <td>119</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>123</td>\n",
       "      <td>102</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           95    0    2   14    5    0   5    0    3    0   124\n",
       "1            0  113    2   17    0    0   0    0    0    0   132\n",
       "2            1    1   66    2   34    0   5    0    3    0   112\n",
       "3            0    1    1  116    3    1   2    0    2    0   126\n",
       "4            0    1   18   22   59    0  14    0    6    0   120\n",
       "5            0    1    0    5    0   88   0   14    3    4   115\n",
       "6           31    1   26   19   13    0  33    0    6    0   129\n",
       "7            0    0    0    0    0   23   0   74    0   10   107\n",
       "8            3    0    6    5    3    4   1    0   99    1   122\n",
       "9            0    0    0    2    0    3   0   20    1   87   113\n",
       "All        130  118  121  202  117  119  60  108  123  102  1200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.71      0.72       189\n",
      "          1       0.98      0.87      0.92       169\n",
      "          2       0.64      0.68      0.66       191\n",
      "          3       0.50      0.86      0.63       173\n",
      "          4       0.54      0.54      0.54       207\n",
      "          5       0.78      0.72      0.74       169\n",
      "          6       0.53      0.25      0.34       189\n",
      "          7       0.76      0.83      0.79       163\n",
      "          8       0.78      0.80      0.79       184\n",
      "          9       0.90      0.78      0.84       166\n",
      "\n",
      "avg / total       0.71      0.70      0.69      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>186</td>\n",
       "      <td>150</td>\n",
       "      <td>203</td>\n",
       "      <td>297</td>\n",
       "      <td>204</td>\n",
       "      <td>156</td>\n",
       "      <td>91</td>\n",
       "      <td>180</td>\n",
       "      <td>188</td>\n",
       "      <td>145</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          135    0    2   29    4    1  10    0    8    0   189\n",
       "1            0  147    1   21    0    0   0    0    0    0   169\n",
       "2            2    0  130    6   42    0   6    0    5    0   191\n",
       "3            7    1    0  149    7    1   5    0    3    0   173\n",
       "4            0    2   37   31  111    0  20    0    6    0   207\n",
       "5            0    0    0    7    0  121   0   27    5    9   169\n",
       "6           41    0   28   29   33    0  48    0   10    0   189\n",
       "7            0    0    0    0    0   21   0  136    0    6   163\n",
       "8            1    0    5   14    7    7   2    1  147    0   184\n",
       "9            0    0    0   11    0    5   0   16    4  130   166\n",
       "All        186  150  203  297  204  156  91  180  188  145  1800"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Parameters Using a Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a cross validation to perfrom an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72641509  0.75235849  0.76832151  0.72985782  0.74109264  0.73031026\n",
      "  0.72966507  0.71223022  0.74278846  0.69711538]\n"
     ]
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "scores = cross_val_score(my_tree, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to using post pruning explicitly is to use a grid search through a large set of possible parameters. Here we try depths between 3 and 20 and different limits on the minimum number of samples per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.7s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   37.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.69214285714285717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.21559262,  0.37969148,  0.36862409,  0.36399138,  0.40306544,\n",
       "         0.37949491,  0.37313533,  0.36128604,  0.36533034,  0.37703013,\n",
       "         0.39513099,  0.39191985,  0.41246796,  0.3892976 ,  0.41713798,\n",
       "         0.41202414,  0.47022986,  0.86847246,  0.89315045,  0.88341177,\n",
       "         0.84894884,  0.76232457,  0.755023  ,  0.75988448,  0.76040852,\n",
       "         0.76149654,  0.75140393,  0.75251269,  0.79328704,  0.80348217,\n",
       "         0.76057446,  0.75257778]),\n",
       " 'mean_score_time': array([ 0.00656283,  0.00609601,  0.00504696,  0.00535059,  0.00586438,\n",
       "         0.00485301,  0.0052917 ,  0.00520837,  0.00480556,  0.00498748,\n",
       "         0.00541556,  0.00547004,  0.00610518,  0.0050776 ,  0.00646257,\n",
       "         0.00498688,  0.00566208,  0.00718594,  0.00741851,  0.0065732 ,\n",
       "         0.00689602,  0.00600362,  0.00556445,  0.00658607,  0.0053215 ,\n",
       "         0.00574934,  0.00659251,  0.00532687,  0.00653696,  0.00581491,\n",
       "         0.00650954,  0.00676405]),\n",
       " 'mean_test_score': array([ 0.48214286,  0.68857143,  0.69214286,  0.69214286,  0.69214286,\n",
       "         0.69214286,  0.69214286,  0.69214286,  0.69214286,  0.69214286,\n",
       "         0.69214286,  0.69214286,  0.69214286,  0.69214286,  0.69214286,\n",
       "         0.69214286,  0.49071429,  0.68571429,  0.68571429,  0.68571429,\n",
       "         0.68571429,  0.68571429,  0.68571429,  0.68571429,  0.68571429,\n",
       "         0.68571429,  0.68571429,  0.68571429,  0.68571429,  0.68571429,\n",
       "         0.68571429,  0.68571429]),\n",
       " 'mean_train_score': array([ 0.4940424 ,  0.72975871,  0.7359501 ,  0.7359501 ,  0.7359501 ,\n",
       "         0.7359501 ,  0.7359501 ,  0.7359501 ,  0.7359501 ,  0.7359501 ,\n",
       "         0.7359501 ,  0.7359501 ,  0.7359501 ,  0.7359501 ,  0.7359501 ,\n",
       "         0.7359501 ,  0.50762404,  0.73047096,  0.73047096,  0.73047096,\n",
       "         0.73047096,  0.73047096,  0.73047096,  0.73047096,  0.73047096,\n",
       "         0.73047096,  0.73047096,  0.73047096,  0.73047096,  0.73047096,\n",
       "         0.73047096,  0.73047096]),\n",
       " 'param_criterion': masked_array(data = ['gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
       "  'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'entropy' 'entropy' 'entropy'\n",
       "  'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
       "  'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_max_depth': masked_array(data = [3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 3 6 9 12 15 18 21 24 27 30 33\n",
       "  36 39 42 45 48],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_samples_split': masked_array(data = [200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200\n",
       "  200 200 200 200 200 200 200 200 200 200 200 200 200 200],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}),\n",
       " 'rank_test_score': array([32, 15,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 31,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16], dtype=int32),\n",
       " 'split0_test_score': array([ 0.4809705 ,  0.6755471 ,  0.68220742,  0.68220742,  0.68220742,\n",
       "         0.68220742,  0.68220742,  0.68220742,  0.68220742,  0.68220742,\n",
       "         0.68220742,  0.68220742,  0.68220742,  0.68220742,  0.68220742,\n",
       "         0.68220742,  0.50047574,  0.67840152,  0.67840152,  0.67840152,\n",
       "         0.67840152,  0.67840152,  0.67840152,  0.67840152,  0.67840152,\n",
       "         0.67840152,  0.67840152,  0.67840152,  0.67840152,  0.67840152,\n",
       "         0.67840152,  0.67840152]),\n",
       " 'split0_train_score': array([ 0.48856053,  0.7264061 ,  0.73355577,  0.73355577,  0.73355577,\n",
       "         0.73355577,  0.73355577,  0.73355577,  0.73355577,  0.73355577,\n",
       "         0.73355577,  0.73355577,  0.73355577,  0.73355577,  0.73355577,\n",
       "         0.73355577,  0.5128694 ,  0.72497617,  0.72497617,  0.72497617,\n",
       "         0.72497617,  0.72497617,  0.72497617,  0.72497617,  0.72497617,\n",
       "         0.72497617,  0.72497617,  0.72497617,  0.72497617,  0.72497617,\n",
       "         0.72497617,  0.72497617]),\n",
       " 'split1_test_score': array([ 0.48331745,  0.70162059,  0.70209724,  0.70209724,  0.70209724,\n",
       "         0.70209724,  0.70209724,  0.70209724,  0.70209724,  0.70209724,\n",
       "         0.70209724,  0.70209724,  0.70209724,  0.70209724,  0.70209724,\n",
       "         0.70209724,  0.48093422,  0.69304099,  0.69304099,  0.69304099,\n",
       "         0.69304099,  0.69304099,  0.69304099,  0.69304099,  0.69304099,\n",
       "         0.69304099,  0.69304099,  0.69304099,  0.69304099,  0.69304099,\n",
       "         0.69304099,  0.69304099]),\n",
       " 'split1_train_score': array([ 0.49952426,  0.73311132,  0.73834443,  0.73834443,  0.73834443,\n",
       "         0.73834443,  0.73834443,  0.73834443,  0.73834443,  0.73834443,\n",
       "         0.73834443,  0.73834443,  0.73834443,  0.73834443,  0.73834443,\n",
       "         0.73834443,  0.50237869,  0.73596575,  0.73596575,  0.73596575,\n",
       "         0.73596575,  0.73596575,  0.73596575,  0.73596575,  0.73596575,\n",
       "         0.73596575,  0.73596575,  0.73596575,  0.73596575,  0.73596575,\n",
       "         0.73596575,  0.73596575]),\n",
       " 'std_fit_time': array([ 0.00417542,  0.02634251,  0.00937593,  0.00456536,  0.01575851,\n",
       "         0.00178409,  0.01247144,  0.00803792,  0.00632751,  0.00547791,\n",
       "         0.01867592,  0.02141595,  0.01903105,  0.00128448,  0.01386797,\n",
       "         0.00313699,  0.00143194,  0.00749862,  0.02066147,  0.00042188,\n",
       "         0.04957092,  0.00312543,  0.00084901,  0.01054251,  0.01309359,\n",
       "         0.00806832,  0.00564682,  0.00935149,  0.00889111,  0.04898989,\n",
       "         0.00109637,  0.00396991]),\n",
       " 'std_score_time': array([  1.70469284e-05,   9.13023949e-04,   3.98993492e-04,\n",
       "          2.85625458e-04,   8.09431076e-04,   4.50611115e-05,\n",
       "          2.36511230e-04,   3.60608101e-04,   6.65187836e-05,\n",
       "          1.55687332e-04,   2.84552574e-04,   6.08921051e-04,\n",
       "          1.10149384e-04,   2.42710114e-04,   5.48362732e-06,\n",
       "          5.59091568e-05,   7.43031502e-04,   6.87837601e-04,\n",
       "          4.08530235e-04,   2.25067139e-04,   2.21014023e-04,\n",
       "          4.83989716e-05,   3.06606293e-04,   3.01122665e-04,\n",
       "          5.73396683e-04,   2.82406807e-04,   2.02655792e-04,\n",
       "          2.89082527e-04,   4.70161438e-04,   3.45826149e-04,\n",
       "          2.96354294e-04,   6.67929649e-04]),\n",
       " 'std_test_score': array([ 0.00117347,  0.01303674,  0.0099449 ,  0.0099449 ,  0.0099449 ,\n",
       "         0.0099449 ,  0.0099449 ,  0.0099449 ,  0.0099449 ,  0.0099449 ,\n",
       "         0.0099449 ,  0.0099449 ,  0.0099449 ,  0.0099449 ,  0.0099449 ,\n",
       "         0.0099449 ,  0.00977075,  0.00731973,  0.00731973,  0.00731973,\n",
       "         0.00731973,  0.00731973,  0.00731973,  0.00731973,  0.00731973,\n",
       "         0.00731973,  0.00731973,  0.00731973,  0.00731973,  0.00731973,\n",
       "         0.00731973,  0.00731973]),\n",
       " 'std_train_score': array([ 0.00548186,  0.00335261,  0.00239433,  0.00239433,  0.00239433,\n",
       "         0.00239433,  0.00239433,  0.00239433,  0.00239433,  0.00239433,\n",
       "         0.00239433,  0.00239433,  0.00239433,  0.00239433,  0.00239433,\n",
       "         0.00239433,  0.00524536,  0.00549479,  0.00549479,  0.00549479,\n",
       "         0.00549479,  0.00549479,  0.00549479,  0.00549479,  0.00549479,\n",
       "         0.00549479,  0.00549479,  0.00549479,  0.00549479,  0.00549479,\n",
       "         0.00549479,  0.00549479])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.731666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.63      0.70       189\n",
      "          1       0.95      0.93      0.94       169\n",
      "          2       0.61      0.72      0.66       191\n",
      "          3       0.77      0.77      0.77       173\n",
      "          4       0.61      0.58      0.60       207\n",
      "          5       0.78      0.82      0.80       169\n",
      "          6       0.40      0.47      0.44       189\n",
      "          7       0.85      0.82      0.83       163\n",
      "          8       0.89      0.81      0.85       184\n",
      "          9       0.86      0.83      0.84       166\n",
      "\n",
      "avg / total       0.74      0.73      0.74      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>225</td>\n",
       "      <td>175</td>\n",
       "      <td>198</td>\n",
       "      <td>178</td>\n",
       "      <td>220</td>\n",
       "      <td>157</td>\n",
       "      <td>167</td>\n",
       "      <td>161</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          119    3   14   14    5    2   30    0    2    0   189\n",
       "1            0  158    1    6    0    0    4    0    0    0   169\n",
       "2            1    0  137    2   27    2   20    0    2    0   191\n",
       "3            6    5    1  134    5    1   18    0    1    2   173\n",
       "4            0    0   35    7  121    1   43    0    0    0   207\n",
       "5            1    0    2    1    0  139    1   11    5    9   169\n",
       "6           24    1   29    9   32    1   89    0    3    1   189\n",
       "7            0    0    0    0    0   19    0  133    2    9   163\n",
       "8            1    0    6    1    7    7   10    1  149    2   184\n",
       "9            0    0    0    1    1    6    5   12    3  138   166\n",
       "All        152  167  225  175  198  178  220  157  167  161  1800"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_tree = tree.DecisionTreeClassifier(min_samples_split=200, criterion='gini', max_depth=8)\n",
    "best_tree = best_tree.fit(X_train, y_train)\n",
    "\n",
    "# visualise the decision tree\n",
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(best_tree, feature_names, 'dt_tuned.png')\n",
    "#Image(filename='dt_tuned.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use the same patterns to train other types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.RandomForestClassifier(n_estimators=300, \\\n",
    "                                           max_features = 3,\\\n",
    "                                           min_samples_split=200)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775833333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.81      0.77       124\n",
      "          1       0.99      0.92      0.96       132\n",
      "          2       0.59      0.72      0.65       112\n",
      "          3       0.67      0.92      0.78       126\n",
      "          4       0.65      0.66      0.66       120\n",
      "          5       1.00      0.84      0.92       115\n",
      "          6       0.59      0.22      0.33       129\n",
      "          7       0.79      0.93      0.86       107\n",
      "          8       0.87      0.88      0.87       122\n",
      "          9       0.87      0.88      0.87       113\n",
      "\n",
      "avg / total       0.78      0.78      0.76      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>138</td>\n",
       "      <td>123</td>\n",
       "      <td>137</td>\n",
       "      <td>172</td>\n",
       "      <td>121</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>126</td>\n",
       "      <td>123</td>\n",
       "      <td>114</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4   5   6    7    8    9   All\n",
       "True                                                           \n",
       "0          101    0    6   12    0   0   2    0    3    0   124\n",
       "1            1  122    2    7    0   0   0    0    0    0   132\n",
       "2            1    0   81    2   19   0   5    0    4    0   112\n",
       "3            1    1    1  116    2   0   4    0    1    0   126\n",
       "4            1    0   17   15   79   0   7    0    1    0   120\n",
       "5            0    0    0    0    0  97   0   11    0    7   115\n",
       "6           33    0   24   16   20   0  29    0    7    0   129\n",
       "7            0    0    0    0    0   0   0  100    0    7   107\n",
       "8            0    0    6    4    1   0   2    1  107    1   122\n",
       "9            0    0    0    0    0   0   0   14    0   99   113\n",
       "All        138  123  137  172  121  97  49  126  123  114  1200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   1.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   1.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.8s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   2.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   1.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.8s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   1.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   1.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   1.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 6, 'min_samples_split': 200, 'n_estimators': 100}\n",
      "0.763571428571\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [200] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Random Forest\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.80      0.76       189\n",
      "          1       0.98      0.95      0.97       169\n",
      "          2       0.72      0.67      0.69       191\n",
      "          3       0.64      0.88      0.74       173\n",
      "          4       0.62      0.73      0.67       207\n",
      "          5       0.97      0.86      0.91       169\n",
      "          6       0.64      0.31      0.41       189\n",
      "          7       0.86      0.91      0.88       163\n",
      "          8       0.94      0.92      0.93       184\n",
      "          9       0.89      0.93      0.91       166\n",
      "\n",
      "avg / total       0.79      0.79      0.78      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>207</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>151</td>\n",
       "      <td>91</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>173</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          151    0    4   22    3    0   7    0    2    0   189\n",
       "1            1  161    0    6    0    0   1    0    0    0   169\n",
       "2            0    0  128    2   48    0  11    0    2    0   191\n",
       "3            8    1    1  152    6    0   5    0    0    0   173\n",
       "4            0    1   19   24  152    0   9    0    2    0   207\n",
       "5            0    0    0    0    0  146   0   14    2    7   169\n",
       "6           46    1   22   23   36    0  58    0    3    0   189\n",
       "7            0    0    0    0    0    3   0  148    0   12   163\n",
       "8            1    0    5    8    0    1   0    0  169    0   184\n",
       "9            0    0    0    1    0    1   0   10    0  154   166\n",
       "All        207  164  179  238  245  151  91  172  180  173  1800"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 50), \\\n",
    "                                      n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.741666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.75      0.74       124\n",
      "          1       0.95      0.86      0.90       132\n",
      "          2       0.53      0.62      0.58       112\n",
      "          3       0.65      0.94      0.77       126\n",
      "          4       0.62      0.71      0.66       120\n",
      "          5       0.85      0.82      0.84       115\n",
      "          6       0.62      0.24      0.35       129\n",
      "          7       0.80      0.80      0.80       107\n",
      "          8       0.81      0.81      0.81       122\n",
      "          9       0.89      0.89      0.89       113\n",
      "\n",
      "avg / total       0.75      0.74      0.73      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>128</td>\n",
       "      <td>119</td>\n",
       "      <td>131</td>\n",
       "      <td>182</td>\n",
       "      <td>136</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>108</td>\n",
       "      <td>122</td>\n",
       "      <td>114</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           93    0   10   13    1    0   4    0    3    0   124\n",
       "1            0  113    2   17    0    0   0    0    0    0   132\n",
       "2            2    0   70    1   30    0   7    0    2    0   112\n",
       "3            0    0    3  118    2    0   1    0    2    0   126\n",
       "4            0    0   12   11   85    0   6    0    6    0   120\n",
       "5            0    6    0    0    0   94   0    8    2    5   115\n",
       "6           29    0   28   19   14    0  31    0    8    0   129\n",
       "7            0    0    0    0    0   13   0   86    0    8   107\n",
       "8            3    0    6    3    4    3   1    3   99    0   122\n",
       "9            1    0    0    0    0    0   0   11    0  101   113\n",
       "All        128  119  131  182  136  110  50  108  122  114  1200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=   9.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=   9.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  18.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  19.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  28.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  27.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total=  37.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total=  35.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total=  50.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total=  49.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total=  56.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total=  54.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 1.2min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 1.2min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 1.4min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 1.4min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 1.6min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 18.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), 'n_estimators': 350}\n",
      "0.513571428571\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.700555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.76      0.73       189\n",
      "          1       0.96      0.84      0.90       169\n",
      "          2       0.65      0.62      0.64       191\n",
      "          3       0.56      0.87      0.68       173\n",
      "          4       0.53      0.78      0.63       207\n",
      "          5       0.84      0.59      0.69       169\n",
      "          6       0.42      0.03      0.05       189\n",
      "          7       0.85      0.84      0.85       163\n",
      "          8       0.77      0.84      0.80       184\n",
      "          9       0.74      0.89      0.81       166\n",
      "\n",
      "avg / total       0.69      0.70      0.67      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>205</td>\n",
       "      <td>148</td>\n",
       "      <td>183</td>\n",
       "      <td>271</td>\n",
       "      <td>303</td>\n",
       "      <td>119</td>\n",
       "      <td>12</td>\n",
       "      <td>161</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          144    1   11   21    3    1   1    0    7    0   189\n",
       "1            0  142    1   26    0    0   0    0    0    0   169\n",
       "2            2    0  119    5   61    0   0    0    4    0   191\n",
       "3           10    0    3  151    5    1   1    0    0    2   173\n",
       "4            0    2   13   27  161    0   0    0    4    0   207\n",
       "5            3    2    0    1    0  100   0   19   11   33   169\n",
       "6           41    0   30   29   72    0   5    0   12    0   189\n",
       "7            0    0    0    0    0   11   0  137    4   11   163\n",
       "8            2    1    6   10    1    1   4    0  154    5   184\n",
       "9            3    0    0    1    0    5   1    5    3  148   166\n",
       "All        205  148  183  271  303  119  12  161  199  199  1800"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 200), \\\n",
    "                                       n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.56      0.55       124\n",
      "          1       0.93      0.65      0.77       132\n",
      "          2       0.49      0.39      0.44       112\n",
      "          3       0.53      0.70      0.60       126\n",
      "          4       0.41      0.42      0.41       120\n",
      "          5       0.58      0.85      0.69       115\n",
      "          6       0.27      0.34      0.30       129\n",
      "          7       0.55      0.44      0.49       107\n",
      "          8       0.83      0.75      0.79       122\n",
      "          9       0.89      0.55      0.68       113\n",
      "\n",
      "avg / total       0.60      0.57      0.57      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>129</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>165</td>\n",
       "      <td>123</td>\n",
       "      <td>169</td>\n",
       "      <td>166</td>\n",
       "      <td>85</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1   2    3    4    5    6   7    8   9   All\n",
       "True                                                         \n",
       "0           70   1   6   15    6    0   24   0    2   0   124\n",
       "1            5  86   0   37    2    0    2   0    0   0   132\n",
       "2            4   0  44    3   29    0   31   0    1   0   112\n",
       "3           10   4   2   88   10    0   12   0    0   0   126\n",
       "4            3   1  18    8   50    0   38   0    2   0   120\n",
       "5            0   0   0    0    0   98    0   7    8   2   115\n",
       "6           33   0  18   10   24    0   44   0    0   0   129\n",
       "7            0   0   0    0    0   51    0  47    3   6   107\n",
       "8            4   0   2    3    2    1   15   3   92   0   122\n",
       "9            0   0   0    1    0   19    0  28    3  62   113\n",
       "All        129  92  90  165  123  169  166  85  111  70  1200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=  16.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=  17.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  34.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  34.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  50.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  50.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total= 1.4min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total= 1.4min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total= 1.7min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total= 1.7min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total= 1.8min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total= 1.8min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 2.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 2.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 2.3min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 2.3min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 2.5min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 29.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), 'n_estimators': 400}\n",
      "0.725476190476\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    " 'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned AdaBoost\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.73      0.76       189\n",
      "          1       1.00      0.93      0.97       169\n",
      "          2       0.57      0.74      0.65       191\n",
      "          3       0.78      0.86      0.82       173\n",
      "          4       0.64      0.56      0.60       207\n",
      "          5       0.71      0.95      0.81       169\n",
      "          6       0.48      0.44      0.46       189\n",
      "          7       0.84      0.60      0.70       163\n",
      "          8       0.90      0.93      0.92       184\n",
      "          9       0.94      0.81      0.87       166\n",
      "\n",
      "avg / total       0.76      0.75      0.75      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>176</td>\n",
       "      <td>158</td>\n",
       "      <td>246</td>\n",
       "      <td>192</td>\n",
       "      <td>181</td>\n",
       "      <td>225</td>\n",
       "      <td>175</td>\n",
       "      <td>115</td>\n",
       "      <td>189</td>\n",
       "      <td>143</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          138    0    0   16    1    0   33    0    1    0   189\n",
       "1            0  158    1    8    0    0    2    0    0    0   169\n",
       "2            0    0  141    1   20    0   29    0    0    0   191\n",
       "3            9    0    2  149    7    0    6    0    0    0   173\n",
       "4            0    0   69    6  116    0   15    0    1    0   207\n",
       "5            0    0    0    0    0  160    0    3    5    1   169\n",
       "6           29    0   28   10   37    0   84    0    1    0   189\n",
       "7            0    0    0    0    0   54    0   97    5    7   163\n",
       "8            0    0    5    2    0    0    6    0  171    0   184\n",
       "9            0    0    0    0    0   11    0   15    5  135   166\n",
       "All        176  158  246  192  181  225  175  115  189  143  1800"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with logistic regression\n",
    "my_model = linear_model.LogisticRegression()\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.75      0.73       124\n",
      "          1       0.98      0.96      0.97       132\n",
      "          2       0.68      0.72      0.70       112\n",
      "          3       0.81      0.87      0.84       126\n",
      "          4       0.75      0.78      0.76       120\n",
      "          5       0.96      0.90      0.93       115\n",
      "          6       0.59      0.47      0.52       129\n",
      "          7       0.81      0.97      0.89       107\n",
      "          8       0.93      0.92      0.93       122\n",
      "          9       0.95      0.87      0.91       113\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>132</td>\n",
       "      <td>129</td>\n",
       "      <td>119</td>\n",
       "      <td>135</td>\n",
       "      <td>126</td>\n",
       "      <td>107</td>\n",
       "      <td>101</td>\n",
       "      <td>128</td>\n",
       "      <td>120</td>\n",
       "      <td>103</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           93    0    2    8    2    0   17    0    2    0   124\n",
       "1            2  127    1    1    0    0    1    0    0    0   132\n",
       "2            3    0   81    1   13    2   10    0    2    0   112\n",
       "3            4    1    2  109    5    0    5    0    0    0   126\n",
       "4            0    0   11    6   94    0    8    0    1    0   120\n",
       "5            0    1    0    0    0  103    0    8    0    3   115\n",
       "6           29    0   20    5   12    0   60    0    3    0   129\n",
       "7            0    0    0    0    0    1    0  104    0    2   107\n",
       "8            1    0    2    5    0    0    0    2  112    0   122\n",
       "9            0    0    0    0    0    1    0   14    0   98   113\n",
       "All        132  129  119  135  126  107  101  128  120  103  1200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.9s\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.8s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.1s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.0s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.3s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.3s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.5s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.3s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.4s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.4s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.7s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.7s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.8s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.6s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.8s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.8s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.8s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.8s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.8s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   49.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 0.6, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
      "0.815714285714\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Logistic Regression\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.826666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.78      0.75       189\n",
      "          1       0.97      0.98      0.98       169\n",
      "          2       0.76      0.74      0.75       191\n",
      "          3       0.79      0.86      0.83       173\n",
      "          4       0.75      0.80      0.78       207\n",
      "          5       0.94      0.88      0.91       169\n",
      "          6       0.61      0.51      0.55       189\n",
      "          7       0.91      0.93      0.92       163\n",
      "          8       0.92      0.91      0.91       184\n",
      "          9       0.93      0.95      0.94       166\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>201</td>\n",
       "      <td>171</td>\n",
       "      <td>186</td>\n",
       "      <td>188</td>\n",
       "      <td>221</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>169</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          147    0    3   12    1    1   23    0    2    0   189\n",
       "1            0  166    1    2    0    0    0    0    0    0   169\n",
       "2            3    0  141    2   27    0   17    0    1    0   191\n",
       "3            9    1    2  149    7    0    5    0    0    0   173\n",
       "4            0    1   16   10  166    0   12    0    2    0   207\n",
       "5            1    0    0    0    0  148    0    8    5    7   169\n",
       "6           38    2   21    9   19    0   96    0    4    0   189\n",
       "7            0    0    0    0    0    6    0  151    1    5   163\n",
       "8            2    0    2    4    1    2    5    1  167    0   184\n",
       "9            1    1    0    0    0    1    0    6    0  157   166\n",
       "All        201  171  186  188  221  158  158  166  182  169  1800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.82      0.73       124\n",
      "          1       0.98      0.95      0.97       132\n",
      "          2       0.53      0.65      0.58       112\n",
      "          3       0.84      0.83      0.84       126\n",
      "          4       0.71      0.64      0.68       120\n",
      "          5       0.99      0.76      0.86       115\n",
      "          6       0.55      0.44      0.49       129\n",
      "          7       0.77      0.96      0.86       107\n",
      "          8       0.96      0.85      0.90       122\n",
      "          9       0.89      0.90      0.89       113\n",
      "\n",
      "avg / total       0.79      0.78      0.78      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>154</td>\n",
       "      <td>128</td>\n",
       "      <td>138</td>\n",
       "      <td>125</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>103</td>\n",
       "      <td>133</td>\n",
       "      <td>108</td>\n",
       "      <td>115</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4   5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          102    0    7    4    0   0   10    0    1    0   124\n",
       "1            1  126    1    3    1   0    0    0    0    0   132\n",
       "2            1    0   73    2   16   0   17    1    2    0   112\n",
       "3            8    2    4  105    5   0    2    0    0    0   126\n",
       "4            3    0   19    7   77   0   13    0    1    0   120\n",
       "5            0    0    1    0    0  87    1   17    0    9   115\n",
       "6           39    0   23    3    7   0   57    0    0    0   129\n",
       "7            0    0    0    0    0   1    0  103    0    3   107\n",
       "8            0    0    9    1    2   0    3    2  104    1   122\n",
       "9            0    0    1    0    0   0    0   10    0  102   113\n",
       "All        154  128  138  125  108  88  103  133  108  115  1200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   6.9s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   6.9s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   7.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   7.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   7.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   7.2s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   8.0s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   7.5s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   7.7s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   7.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   8.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   7.7s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   7.3s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   7.5s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   7.5s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   7.6s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   7.5s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   7.3s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   7.4s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n",
      "0.779285714286\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned kNN\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.802222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77       189\n",
      "          1       0.99      0.97      0.98       169\n",
      "          2       0.66      0.75      0.70       191\n",
      "          3       0.83      0.84      0.84       173\n",
      "          4       0.76      0.69      0.72       207\n",
      "          5       0.98      0.70      0.82       169\n",
      "          6       0.60      0.49      0.54       189\n",
      "          7       0.81      0.95      0.87       163\n",
      "          8       0.97      0.90      0.93       184\n",
      "          9       0.85      0.92      0.88       166\n",
      "\n",
      "avg / total       0.81      0.80      0.80      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>233</td>\n",
       "      <td>166</td>\n",
       "      <td>218</td>\n",
       "      <td>176</td>\n",
       "      <td>188</td>\n",
       "      <td>122</td>\n",
       "      <td>153</td>\n",
       "      <td>192</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          162    0    5    9    2    0   10    0    1    0   189\n",
       "1            2  164    2    1    0    0    0    0    0    0   169\n",
       "2            3    0  144    1   21    0   21    0    1    0   191\n",
       "3           13    1    3  146    7    0    3    0    0    0   173\n",
       "4            2    1   32   10  143    0   18    0    1    0   207\n",
       "5            1    0    1    0    0  119    1   24    1   22   169\n",
       "6           47    0   25    9   15    0   92    0    1    0   189\n",
       "7            0    0    0    0    0    2    0  155    1    5   163\n",
       "8            3    0    6    0    0    0    7    2  166    0   184\n",
       "9            0    0    0    0    0    1    1   11    0  153   166\n",
       "All        233  166  218  176  188  122  153  192  172  180  1800"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(300, 100))\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8275\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.81      0.74       124\n",
      "          1       0.99      0.96      0.98       132\n",
      "          2       0.77      0.64      0.70       112\n",
      "          3       0.88      0.87      0.87       126\n",
      "          4       0.70      0.80      0.74       120\n",
      "          5       0.96      0.92      0.94       115\n",
      "          6       0.63      0.52      0.57       129\n",
      "          7       0.84      0.96      0.90       107\n",
      "          8       0.91      0.93      0.92       122\n",
      "          9       0.94      0.87      0.90       113\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>93</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>110</td>\n",
       "      <td>106</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>104</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2    3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          101    0   1    6    2    0   13    0    1    0   124\n",
       "1            2  127   1    1    0    0    1    0    0    0   132\n",
       "2            1    0  72    1   21    0   12    0    5    0   112\n",
       "3            5    1   0  109    7    0    3    0    1    0   126\n",
       "4            3    0   7    4   96    0    9    0    1    0   120\n",
       "5            0    0   0    0    0  106    0    5    0    4   115\n",
       "6           37    0  11    1   10    0   67    0    3    0   129\n",
       "7            0    0   0    0    0    2    0  103    0    2   107\n",
       "8            0    0   1    2    2    0    1    2  114    0   122\n",
       "9            0    0   0    0    0    2    0   13    0   98   113\n",
       "All        149  128  93  124  138  110  106  123  125  104  1200"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=  19.8s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=  13.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   8.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   9.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=   9.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  11.4s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  14.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  16.2s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=   9.0s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  11.6s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  14.8s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  16.9s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   7.9s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   7.4s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  22.6s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  13.7s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=   9.7s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  15.4s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=  16.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=  13.3s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  14.1s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  18.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=   8.5s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  10.9s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=  16.4s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=  17.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=   7.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  11.5s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  10.5s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  11.4s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   8.7s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=  15.3s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  15.5s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=   6.3s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  12.6s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (400, 200)}\n",
      "0.836904761905\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neural_network.MLPClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned MLP\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.852777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.78      0.79       189\n",
      "          1       0.98      0.98      0.98       169\n",
      "          2       0.85      0.70      0.77       191\n",
      "          3       0.79      0.93      0.85       173\n",
      "          4       0.77      0.81      0.79       207\n",
      "          5       0.92      0.94      0.93       169\n",
      "          6       0.63      0.64      0.64       189\n",
      "          7       0.92      0.95      0.94       163\n",
      "          8       0.98      0.92      0.95       184\n",
      "          9       0.96      0.93      0.95       166\n",
      "\n",
      "avg / total       0.86      0.85      0.85      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>186</td>\n",
       "      <td>169</td>\n",
       "      <td>156</td>\n",
       "      <td>205</td>\n",
       "      <td>217</td>\n",
       "      <td>172</td>\n",
       "      <td>192</td>\n",
       "      <td>168</td>\n",
       "      <td>173</td>\n",
       "      <td>162</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          148    0    2   15    2    0   21    0    1    0   189\n",
       "1            0  166    0    3    0    0    0    0    0    0   169\n",
       "2            2    0  133    3   28    0   24    0    1    0   191\n",
       "3            4    1    0  161    1    0    6    0    0    0   173\n",
       "4            0    1   12   11  168    1   14    0    0    0   207\n",
       "5            0    0    0    0    0  159    0    4    1    5   169\n",
       "6           30    1    9   10   16    1  121    0    1    0   189\n",
       "7            0    0    0    0    0    6    0  155    0    2   163\n",
       "8            2    0    0    2    2    1    6    2  169    0   184\n",
       "9            0    0    0    0    0    4    0    7    0  155   166\n",
       "All        186  169  156  205  217  172  192  168  173  162  1800"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Better Tree': 0.69666666666666666,\n",
       " 'Simple Tree': 0.72722222222222221,\n",
       " 'Tuned AdaBoost': 0.74944444444444447,\n",
       " 'Tuned Bagging': 0.7005555555555556,\n",
       " 'Tuned Logistic Regression': 0.82666666666666666,\n",
       " 'Tuned MLP': 0.85277777777777775,\n",
       " 'Tuned Random Forest': 0.78833333333333333,\n",
       " 'Tuned Tree': 0.73166666666666669,\n",
       " 'Tuned kNN': 0.80222222222222217}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_test_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAD8CAYAAABevCxMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130e77cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': 0.5675,\n",
       " 'Bagging': 0.7416666666666667,\n",
       " 'Better Tree': 0.69166666666666665,\n",
       " 'Logistic Regression': 0.8175,\n",
       " 'MLP': 0.82750000000000001,\n",
       " 'Random Forest': 0.77583333333333337,\n",
       " 'Simple Tree': 0.71666666666666667,\n",
       " 'kNN': 0.78000000000000003}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_valid_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAD8CAYAAAD61pSfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG7xJREFUeJzt3XucnVV97/HP1yC3AkEFbRovYzFc5JZDAl6KCHLEVqlI\nxSNKFdSWqtW29kiNtkdpixVf6DlIqZdoES1VeFm1oqCAF8AqKBNIMkCFqqAF23JRUu5I8jt/7JVm\nO80wz0xmZs8kn/frlVeevZ611vOblZAv69nP7ElVIUmSHtmjBl2AJElzgYEpSVIHBqYkSR0YmJIk\ndWBgSpLUgYEpSVIHBqYkSR0YmJIkdWBgSpLUwVaDLkCTt8suu9TQ0NCgy5CkOWXFihV3VNWuEx1n\nYM5hQ0NDDA8PD7oMSZpTkvxoMuO8JStJUgcGpiRJHRiYkiR1YGBKktSBgSlJUgcGpiRJHRiYkiR1\nYGBKktSBH1wwh43cuoahZRcMugxJm4mbT33RoEuY1dxhSpLUgYEpSVIHBqYkSR0YmJIkdWBgSpLU\ngYEpSVIHBuY0SFJJzul7vVWS25N8qb0+IcmZGxl3c5KRJKuTXJzkl2eybknS2AzM6XEvsE+S7drr\n5wO3dhx7WFXtBwwD75iO4iRJE2dgTp8LgfXfBfwK4NMTHH858LQprUiSNGkG5vQ5Fzg2ybbAfsB3\nJjj+SGBkdGOSE5MMJxlee9+aKShTktSFgTlNqmo1MERvd3nhBIZ+I8lKYCfgPRuZd3lVLa2qpfO2\nnz8ltUqSxudnyU6v84H3AYcCj+s45rCqumPaKpIkTYqBOb3OAu6qqpEkhw66GEnS5HlLdhpV1S1V\ndcYYp09IckvfryfOaHGSpAlxhzkNqmqHjbRdClzajs8Gzt7I0KHpq0qStCncYUqS1IGBKUlSBwam\nJEkdGJiSJHVgYEqS1IFPyc5h+y6cz/CpLxq/oyRpk7nDlCSpAwNTkqQODExJkjowMCVJ6sCHfuaw\nkVvXMLTsgkGXIWmWuNmHAKeVO0xJkjowMCVJ6sDAlCSpAwNTkqQODExJkjowMKdYkqEk145qOzRJ\nJfnNvrYvJTm0HV+aZLjv3NIkl85UzZKk8RmYM+cW4E8f4fzjk/zGTBUjSZoYA3MaJfnVJNcABwKr\ngDVJnj9G99N45ECVJA2QgTlNkuwBfBY4AbiqNb8b+LMxhlwBPJTksOmvTpI0UQbm9NgV+AJwXFWt\nWt9YVZcDJDl4jHGnMHag0saemGQ4yfDa+9ZMVb2SpHEYmNNjDfBjYGPBOOYus6q+DmwHPHOsiatq\neVUtraql87afPxW1SpI6MDCnx0PA0cCrk7yy/0RVXQw8BthvjLGnAH8yveVJkibKwJwmVXUvcCTw\nFmCnUaffDTxpjHEXArdPb3WSpInyp5VMsaq6GdinHd9F7wlZgPP7+pwPpO/1oaPmWDLddUqSJsYd\npiRJHRiYkiR1YGBKktSBgSlJUgcGpiRJHfiU7By278L5DJ/6okGXIUlbBHeYkiR1YGBKktSBgSlJ\nUgcGpiRJHfjQzxw2cusahpZdMOgyJM1hN/vgYGfuMCVJ6sDAlCSpAwNTkqQODExJkjowMCVJ6mDc\nwExyz6ZeJMmvJPmHRzi/c5I3du2/kfFnJ7kpycokq5Icvqk1T6Ukr0/y6kHXIUmavBnZYVbVT6rq\nmEfosjPwxgn035iTqmox8EfAhydR5n+TZEq+7aaqPlxVn5yKuSRJgzGpwEwylOTrSVYn+VqSJ7f2\n3ZJcmWQkySnrd6et/7XteO8k3227wdVJFgGnAru1ttNG9Z+X5H1Jrm393zxOeVcAC/tqXZLksiQr\nklyUZEFrP7DNt/6a6693QpLzk3wd+FprOynJVa3/n7e2X0pyQdvRXpvk5a391CTXt77va20nJ3lr\nO17c1mh1ks8neUxrvzTJe9va3JjkOZP5s5EkTY/J7jD/GvhEVe0H/D1wRmv/APCBqtoXuGWMsa9v\nfRYDS1u/ZcAPqmpxVZ00qv+JwBCwuO96j+TXgX8ESPLoVusxVbUEOAt4d+v3ceD3Wh1rR81xQBvz\n3CRHAIuAg4DFwJIkh7Tr/KSq9q+qfYCvJHkccDSwd6v1lI3U90ngbe38CPCuvnNbVdVB9HbJ79rI\nWEnSgEw2MJ8FfKod/x1wcF/7Z9rxp0YPaq4A3pHkbcBTqur+ca71P4GPVNXDAFX10zH6nZbkxnbd\n97a2PYB9gEuSrAT+DHhikp2BHavqijFqvaTvOke0X9cAVwN70gvQEeD5bVf4nKpaA6wBHgD+Nslv\nAff1T5pkPrBzVV3Wmj4BHNLX5XPt9xX0/ifhv0lyYpLhJMNr71szxlJIkqbajD8lW1WfAl4M3A9c\nmOR5UzT1SVW1O/A2ejtJgADXtZ3r4qrat6qO6DDXvX3HAd7TN8fTqupvq+pGejvREeCUJO9soX4Q\n8A/AkcBXJvg1PNh+X8sYH1tYVcuramlVLZ23/fwJTi9JmqzJBua3gWPb8XHAN9vxlcBL2/GxowcB\nJPlV4IdVdQbwBWA/4G5gxzGudQnwe+sfwEny2HFqOxN4VJIXADcAuyZ5Vhv76CR7V9VdwN1JnvFI\ntTYXAa9NskObY2GSxyf5FeC+qjoHOA04oPWZX1UXAm8B9u+fqO1Cf9b3/uSrgMuQJM16XZ4C3T5J\n//uR/xd4M/DxJCcBtwOvaef+CDgnyZ/S211t7J7h/wJeleTnwL8Df1VVP03yrfbgzZeBv+nr/zFg\nd2B1G/NReqG4UVVVSU4B/qSqLkpyDHBGux26FXA6cB3wOuCjSdbRC62N3t+sqouT7AVckQTgHuC3\ngafRuw28Dvg58AZ6of+FJNvS25n+8UamPB74cJLtgR/2rZ0kaRZLVU3dZL0QuL+F1rHAK6rqqCm7\nwBRKskNVrX+KdxmwoKr+cMBlTcg2CxbVguNPH3QZkuawLfGnlSRZUVVLJzpuqn+81xLgzPS2YncB\nr53i+afSi5K8nd4a/Ag4YbDlSJJmsykNzKr6JqPet5utquo84LxB1yFJmhv8LFlJkjowMCVJ6sDA\nlCSpg6l+6EczaN+F8xneAp9wk6RBcIcpSVIHBqYkSR0YmJIkdWBgSpLUgQ/9zGEjt65haNkFgy5D\nmlFb4ke5aXZwhylJUgcGpiRJHRiYkiR1YGBKktSBgSlJUgcGpiRJHWxRgZnkJUkqyZ5jnD87yTHj\nzHF2kpuSrEzyvSTvmoYanz6Vc0qSNt0WFZjAK4B/ar9vipOqajGwGDg+yVM3ubINXgIYmJI0y2wx\ngZlkB+Bg4HXAsa0tSc5MckOSrwKP7+v/ziRXJbk2yfIk2ci027bf721jDk9yTZKRJGcl2Wac9lOT\nXJ9kdZL3JXk28GLgtLaD3W261kOSNDFbTGACRwFfqaobgTuTLAGOBvagt6N7NfDsvv5nVtWBVbUP\nsB1wZN+505KsBG4Bzq2q25JsC5wNvLyq9qX3KUpveIT2x7Xr711V+wGnVNW3gfNpO9iq+sHoLyLJ\niUmGkwyvvW/NVK2NJGkcW1JgvgI4tx2f214fAny6qtZW1U+Ar/f1PyzJd5KMAM8D9u47t/6W7C8D\nh7ed4R7ATS2QAT7R5h+rfQ3wAPC3SX4LuK/LF1FVy6tqaVUtnbf9/Il8/ZKkTbBFfJZsksfSC719\nkxQwDyjg82P03xb4ILC0qv41yclsuP36X6rqniSX0rvVe9FEaqqqh5McBBwOHAO8qdUoSZqFtpQd\n5jHA31XVU6pqqKqeBNwE3Am8PMm8JAuAw1r/9eF4R3vvc6NPzibZCngG8APgBmAoydPa6VcBl43V\n3uadX1UXAm8B9m/n7wZ2nJKvWpI0ZbaUwHwF/303+VlgAfAvwPXAJ4ErAKrqLuCjwLX0do5XjRq7\n/j3M1cAI8LmqegB4DfCZdht3HfDhsdrpheKXkqym9+TuH7e5zwVOag8J+dCPJM0SqapB16BJ2mbB\nolpw/OmDLkOaUf54L22qJCuqaulEx20pO0xJkjaJgSlJUgcGpiRJHRiYkiR1YGBKktTBFvHBBZur\nfRfOZ9gnBiVpRrjDlCSpAwNTkqQODExJkjowMCVJ6sCHfuawkVvXMLTsgkGXIWka+BGAs487TEmS\nOjAwJUnqwMCUJKkDA1OSpA4MTEmSOtjiAzPJ2iQrk6xKcnWSZ0/DNZYmOWOq55UkzRy/rQTur6rF\nAEleALwHeO5UXqCqhoHhqZxTkjSztvgd5ig7AT8DSLJDkq+1XedIkqPWd0ryf5LckOSfknw6yVtb\n+4FJVrcd62lJrm3thyb5Ujs+OclZSS5N8sMkfzDevJKkwXOHCdslWQlsCywAntfaHwCOrqr/TLIL\ncGWS84GlwEuB/YFHA1cDK9qYjwO/W1VXJDn1Ea65J3AYsCNwQ5IPAYsfYV5J0oAZmL94S/ZZwCeT\n7AME+KskhwDrgIXAE4BfA75QVQ8ADyT5Yhu7M7BjVV3R5v0UcOQY17ygqh4EHkxy2yPNO1qSE4ET\nAebttOsmfumSpK4MzD5tZ7gLsCvwwvb7kqr6eZKb6e1Cp8KDfcdrmcCfQ1UtB5YDbLNgUU1RPZKk\ncfgeZp8kewLzgDuB+cBtLSwPA57Sun0L+M0k2ybZgbaLrKq7gLuTPKP1O3aCl9/ovJKk2cEd5ob3\nMKF3G/b4qlqb5O+BLyYZofeE6/cAquqq9l7mauA/gBFgTRv/OuCjSdYBl/W1j2uceSVJA7bFB2ZV\nzRuj/Q7gWWMMe19VnZxke+ByNjycc11V7QeQZBntW0mq6lLg0nZ88qjr7NNhXknSgG3xgTlJy5M8\nnd57mp+oqqtb+4uSvJ3euv4IOGGK5pUkDZiBOQlV9cox2s8DzpvqeSVJg+dDP5IkdWBgSpLUgYEp\nSVIHvoc5h+27cD7Dp75o0GVI0hbBHaYkSR0YmJIkdWBgSpLUgYEpSVIHPvQzh43cuoahZRcMugxJ\ns8DNPgA47dxhSpLUgYEpSVIHBqYkSR0YmJIkdWBgSpLUwUACM8naJCuTXJvki0l2nqJ5h5JcOxVz\njZr35CS3tppXJjl1qq/Rd63FSV44XfNLkiZnUDvM+6tqcVXtA/wU+P0B1TER/6/VvLiqlnUdlGTe\nBK+zGDAwJWmWmQ23ZK8AFgIk2SHJ15JcnWQkyVGtfSjJPyf5aJLrklycZLt2bkmSVUlW0Re8SbZN\n8vE2zzVJDmvtJyT5xySXJLk5yZuS/HHrc2WSx3YtPMnhbdxIkrOSbNPab07y3iRXAy9LsluSryRZ\nkeSbSfZs/V7WdtmrklyeZGvgL4CXt53sy6dkhSVJm2yggdl2X4cD57emB4Cjq+oA4DDg/UnSzi0C\n/qaq9gbuAl7a2j8OvLmq9h81/e8DVVX7Aq8APpFk23ZuH+C3gAOBdwP3VdX/oBferx6j3Lf03ZJ9\nQZvrbODl7RpbAW/o639nVR1QVecCy1uNS4C3Ah9sfd4JvKDV/uKqeqi1ndd2sueNs4SSpBkyqMDc\nLslK4N+BJwCXtPYAf5VkNfBVejvPJ7RzN1XVyna8Ahhq733uXFWXt/a/67vGwcA5AFX1PeBHwO7t\n3Deq6u6quh1YA3yxtY8AQ2PU3H9L9iJgj1bTje38J4BD+vqfB71dM/Bs4DPta/4IsKD1+RZwdpLf\nBTrduk1yYpLhJMNr71vTZYgkaQoM9D1M4Cn0QnL9rdTjgF2BJe38fwDrd4UP9o1fy6Z9rF//XOv6\nXq/bxHn73dt+fxRwV1/YLq6qvQCq6vXAnwFPAlYkedx4k1bV8qpaWlVL520/f4pKlSSNZ6C3ZKvq\nPuAPgP+dZCtgPnBbVf28vef4lHHG3wXcleTg1nRc3+lvrn+dZHfgycANU1j+DfR2uU9rr18FXLaR\nGv8TuCnJy1otSbJ/O96tqr5TVe8EbqcXnHcDO05hnZKkKTDwh36q6hpgNb33Gf8eWJpkhN57id/r\nMMVrgL9ptzvT1/5B4FFtrvOAE6rqwY1NMMm6H2jX/ky7xjrgw2N0Pw54XXsw6TrgqNZ+Wntg6Frg\n28Aq4BvA033oR5Jml1TVoGvQJG2zYFEtOP70QZchaRbwp5V0l2RFVS2d6LiB7zAlSZoLDExJkjow\nMCVJ6sDAlCSpAwNTkqQOpuqb9DUA+y6cz7BPxknSjHCHKUlSBwamJEkdGJiSJHVgYEqS1IEP/cxh\nI7euYWjZBYMuQ9JG+FF1mx93mJIkdWBgSpLUgYEpSVIHBqYkSR0YmJIkdWBgSpLUwZwPzCRrk6xM\nsirJ1UmePU7/nZO8se/1UJJXbmIN32k1/DjJ7e14ZZKhTZlXkjR7zPnABO6vqsVVtT/wduA94/Tf\nGXhj3+shYEKBmeQXvn+1qp5RVYuBdwLntXoWV9XNo8bNm8h1JEmzx+YQmP12An62/kWSk5JclWR1\nkj9vzacCu7Ud4Gnt9XPa67ckmZfktL5xv9fmOjTJN5OcD1zfpZgkWyW5K8npSVYDByU5MMllSVYk\n+XKSJ7S+i5Jc1NovT7L7FK6LJGkTbQ6f9LNdkpXAtsAC4HkASY4AFgEHAQHOT3IIsAzYp+0ISXIo\n8NaqOrK9PhFYU1UHJtkG+FaSi9u1Dmhjb5pAffOBy6vqj9p83wBeXFV3JDkO+EvgRGA58DtV9YMk\nvwacCRwxerJW34kA83badQJlSJI2xeYQmPf3hd+zgE8m2Yde2BwBXNP67UAvQH88znxHAPslOaa9\nnt/GPQR8d4JhSRv3+Xa8F7A38NUkAPOAW5LsDDwT+GxrhzH+bKpqOb1wZZsFi2qCtUiSJmlzCMz/\nUlVXJNkF2JXervI9VfWR/j4dHsQJ8OaqumjUuEOBeydR1v1VtT7YAqyuqueMmvsxwB3rg1+SNPts\nVu9hJtmT3q7tTuAi4LVJdmjnFiZ5PHA3sGPfsNGvLwLekOTRbdzuSX5pikq8HliY5KA299ZJ9q6q\nnwH/luTo1v6oJPtP0TUlSVNgc9hhrn8PE3o7uOOrai1wcZK9gCvabc57gN9u7xF+K8m1wJeBdwBr\nk6wCzgY+QO/J2avTG3g78JKpKLSqHmy3es9IshO9cH8/cB1wLPChJCcDWwPnAKum4rqSpE2XDXcL\nNddss2BRLTj+9EGXIWkj/PFes1eSFVW1dKLjNqtbspIkTRcDU5KkDgxMSZI6MDAlSerAwJQkqYPN\n4dtKtlj7LpzPsE/iSdKMcIcpSVIHBqYkSR0YmJIkdWBgSpLUgQ/9zGEjt65haNkFgy5D0iT40Xlz\njztMSZI6MDAlSerAwJQkqQMDU5KkDgxMSZI6mJOBmeRPk1yXZHWSlUme0do/luTpU3SNeybQ9zut\njh8nub0dr0wyNBW1SJIGb859W0mSZwFHAgdU1YNJdgG2Bqiq3xlETVW1PrBPAJZW1Zs21i/JvKpa\nO5O1SZKmxlzcYS4A7qiqBwGq6o6q+glAkkuTLG3H9yQ5re1Ev5rkoHb+h0le3PqckOQLrf1fkrxr\nYxdMclKSq9qO9s+7FppkqyR3JTk9yWrgoCQHJrksyYokX07yhNZ3UZKLWvvlSXbftGWSJE2luRiY\nFwNPSnJjkg8mee4Y/X4J+HpV7Q3cDZwCPB84GviLvn4HAS8F9gNetj5w10tyBLCo9VsMLElyyATq\nnQ9cXlX7AVcDHwBeWlVLgHOAv2z9lgNvbO1vB86cwDUkSdNszt2Srap7kiwBngMcBpyXZFlVnT2q\n60PAV9rxCPBgVf08yQgw1Nfvkqq6EyDJ54CDgeG+80e0X9e01zvQC9DLO5b8EPD5drwXsDfw1SQA\n84BbkuwMPBP4bGuHMf5skpwInAgwb6ddO5YgSdpUcy4wAdr7gJcCl7YAPB44e1S3n1dVteN1wPpb\nuOuS9H/dNWrc6NcB3lNVH5lkuff31RFgdVU95xcukDyG3m3mxeNNVlXL6e1G2WbBotG1SpKmyZy7\nJZtkjySL+poWAz/ahCmfn+SxSbYDXgJ8a9T5i4DXJtmhXX9hksdP8lrXAwuTHNTm2jrJ3lX1M+Df\nkhzd2h+VZP9JXkOSNA3m4g5zB+Cv223Mh4Hv025RTtJ3gc8CTwTOqar+27FU1cVJ9gKuaLdL7wF+\nG7htohdqT/UeA5yRZCd6t2TfD1wHHAt8KMnJ9J76PQdYNdkvSpI0tbLhbuGWZ7xvA5nttlmwqBYc\nf/qgy5A0Cf60ksFJsqKqlo7f8xfNuVuykiQNwly8JTtl2pO1Zw+4DEnSHOAOU5KkDgxMSZI6MDAl\nSepgi34Pc67bd+F8hn3STpJmhDtMSZI6MDAlSerAwJQkqQMDU5KkDgxMSZI6MDAlSerAwJQkqQMD\nU5KkDgxMSZI62KJ/HuZcl+Ru4IZB1zFL7ALcMegiZgnXYgPXYgPXYoM9qmrHiQ7yo/Hmthsm80NQ\nN0dJhl2LHtdiA9diA9digyTDkxnnLVlJkjowMCVJ6sDAnNuWD7qAWcS12MC12MC12MC12GBSa+FD\nP5IkdeAOU5KkDgzMOSDJrye5Icn3kyzbyPkkOaOdX53kgEHUORM6rMVxbQ1Gknw7yf6DqHO6jbcO\nff0OTPJwkmNmsr6Z1GUtkhyaZGWS65JcNtM1zpQO/33MT/LFJKvaWrxmEHXOhCRnJbktybVjnJ/4\nv5tV5a9Z/AuYB/wA+FVga2AV8PRRfV4IfBkI8EzgO4Oue4Br8WzgMe34NzbHteiyDn39vg5cCBwz\n6LoH+HdiZ+B64Mnt9eMHXfcA1+IdwHvb8a7AT4GtB137NK3HIcABwLVjnJ/wv5vuMGe/g4DvV9UP\nq+oh4FzgqFF9jgI+WT1XAjsnWTDThc6Acdeiqr5dVT9rL68EnjjDNc6ELn8nAN4MfBa4bSaLm2Fd\n1uKVwOeq6scAVbW5rkeXtShgxyQBdqAXmA/PbJkzo6oup/f1jWXC/24amLPfQuBf+17f0tom2mdz\nMNGv83X0/g9yczPuOiRZCBwNfGgG6xqELn8ndgcek+TSJCuSvHrGqptZXdbiTGAv4CfACPCHVbVu\nZsqbdSb876af9KPNUpLD6AXmwYOuZUBOB95WVet6m4kt2lbAEuBwYDvgiiRXVtWNgy1rIF4ArASe\nB+wGXJLkm1X1n4Mta24wMGe/W4En9b1+YmubaJ/NQaevM8l+wMeA36iqO2eotpnUZR2WAue2sNwF\neGGSh6vqH2emxBnTZS1uAe6sqnuBe5NcDuwPbG6B2WUtXgOcWr038b6f5CZgT+C7M1PirDLhfze9\nJTv7XQUsSvLUJFsDxwLnj+pzPvDq9tTXM4E1VfVvM13oDBh3LZI8Gfgc8KrNeAcx7jpU1VOraqiq\nhoB/AN64GYYldPvv4wvAwUm2SrI98Azgn2e4zpnQZS1+TG+nTZInAHsAP5zRKmePCf+76Q5zlquq\nh5O8CbiI3lNwZ1XVdUle385/mN5TkC8Evg/cR+//Ijc7HdfincDjgA+23dXDtZl94HTHddgidFmL\nqvrnJF8BVgPrgI9V1Ua/1WAu6/j34i+Bs5OM0Hs69G1VtVn+BJMknwYOBXZJcgvwLuDRMPl/N/2k\nH0mSOvCWrCRJHRiYkiR1YGBKktSBgSlJUgcGpiRJHRiYkiR1YGBKktSBgSlJUgf/HwOjOJ9PkC3G\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e4bcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tuned AdaBoost': {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=200,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'n_estimators': 400},\n",
       " 'Tuned Bagging': {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=200,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'n_estimators': 350},\n",
       " 'Tuned Logistic Regression': {'C': 0.6,\n",
       "  'max_iter': 1000,\n",
       "  'multi_class': 'ovr',\n",
       "  'solver': 'liblinear'},\n",
       " 'Tuned MLP': {'alpha': 0.001, 'hidden_layer_sizes': (400, 200)},\n",
       " 'Tuned Random Forest': {'max_features': 6,\n",
       "  'min_samples_split': 200,\n",
       "  'n_estimators': 100},\n",
       " 'Tuned Tree': {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       " 'Tuned kNN': {'n_neighbors': 6}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_tuned_params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Best Model On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = linear_model.LogisticRegression(C=0.4,max_iter = 1000,multi_class='ovr',solver='liblinear')\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8499\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.79      0.80      1000\n",
      "          1       0.98      0.96      0.97      1000\n",
      "          2       0.82      0.71      0.76      1000\n",
      "          3       0.78      0.92      0.85      1000\n",
      "          4       0.76      0.78      0.77      1000\n",
      "          5       0.93      0.91      0.92      1000\n",
      "          6       0.65      0.66      0.65      1000\n",
      "          7       0.89      0.92      0.91      1000\n",
      "          8       0.98      0.91      0.95      1000\n",
      "          9       0.93      0.94      0.94      1000\n",
      "\n",
      "avg / total       0.85      0.85      0.85     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>29</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>921</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>779</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>940</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>985</td>\n",
       "      <td>981</td>\n",
       "      <td>869</td>\n",
       "      <td>1179</td>\n",
       "      <td>1030</td>\n",
       "      <td>980</td>\n",
       "      <td>1015</td>\n",
       "      <td>1025</td>\n",
       "      <td>930</td>\n",
       "      <td>1006</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2     3     4    5     6     7    8     9    All\n",
       "True                                                                   \n",
       "0          793    5    6    69     3    2   118     0    4     0   1000\n",
       "1            1  960    4    29     0    1     5     0    0     0   1000\n",
       "2           20    1  709    29   143    2    92     0    4     0   1000\n",
       "3           23   12    7   921    18    0    19     0    0     0   1000\n",
       "4            0    1   66    64   779    0    89     0    1     0   1000\n",
       "5            2    0    0     1     0  912     1    55    3    26   1000\n",
       "6          137    2   66    55    80    0   655     0    5     0   1000\n",
       "7            0    0    0     0     0   44     0   917    0    39   1000\n",
       "8            8    0   11    11     7    8    35     6  913     1   1000\n",
       "9            1    0    0     0     0   11     1    47    0   940   1000\n",
       "All        985  981  869  1179  1030  980  1015  1025  930  1006  10000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
